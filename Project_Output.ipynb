{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    import os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import argparse\n",
    "    import random\n",
    "    import sklearn\n",
    "    import sklearn.metrics as metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    #set the matplotlib backend so plots can be saved in the background\n",
    "    #necessary since running on Google Cloud  \n",
    "    import matplotlib\n",
    "    %matplotlib inline\n",
    "    matplotlib.use('Agg') \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    #Utilize GPUs\n",
    "    import tensorflow as tf\n",
    "    #Setup Keras \n",
    "    from keras.models import Sequential, Model\n",
    "    from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "    from keras.layers.core import Activation, Flatten, Dense\n",
    "    from keras.layers import BatchNormalization, Dropout, LeakyReLU\n",
    "    from keras.optimizers import Adam, SGD, Adagrad\n",
    "    from keras import backend as K \n",
    "    K.tensorflow_backend._get_available_gpus()\n",
    "    \n",
    "    from keras.preprocessing.image import ImageDataGenerator    \n",
    "    from keras.callbacks import History\n",
    "    \n",
    "    #Setup VGG16\n",
    "    from keras.applications import vgg16\n",
    "    from keras.preprocessing import image\n",
    "    from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(filename, numberofimages = 1462):\n",
    "\n",
    "    global classes\n",
    "    global number_in_class\n",
    "    classes = []\n",
    "    number_in_class = []\n",
    "\n",
    "    path, dirs, files = next(os.walk(\"../\" + filename + \"/\"))  \n",
    "\n",
    "    for dir in dirs:\n",
    "        path2, dirs2, files2 = next(os.walk(\"../\" + filename + \"/\" + dir))  \n",
    "        classes.append(dir)\n",
    "        number_in_class.append(len(files2)-1)\n",
    "\n",
    "    print(number_in_class)\n",
    "    global number_training\n",
    "    global number_tested\n",
    "    number_training = sum(number_in_class)\n",
    "    number_tested = numberofimages - number_training\n",
    "    return classes  \n",
    "    return number_in_class\n",
    "    return number_training\n",
    "    return number_tested\n",
    "\n",
    "def graph(xlabel, ylabel, classes, number_in_class):   \n",
    "    df = pd.DataFrame({xlabel:classes, ylabel:number_in_class})\n",
    "    df = df.sort_values([ylabel], ascending=False)\n",
    "    df.plot(kind='bar', x = xlabel, y = ylabel, legend=False, \n",
    "            color=['tab:blue','tab:orange', 'tab:green', 'tab:red', \n",
    "                   'tab:purple', 'tab:brown', 'tab:pink',\n",
    "                   'tab:olive', 'tab:cyan'], width = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count('boats_train_test/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build(num_classes, input_size, learnrate, EPOCHS, pad):\n",
    "     \n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "\n",
    "    #Convolution Layer\n",
    "    model.add(Conv2D(32, (3, 3), padding = pad, input_shape = (56,56,3)))\n",
    "    model.add(LeakyReLU(alpha = 0.1))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    #A Second Convolutional Layer\n",
    "    model.add(Conv2D(64, (3, 3), padding = pad))\n",
    "    model.add(LeakyReLU(alpha = 0.1))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    #Third Convolutional Layer\n",
    "    model.add(Conv2D(128, (3, 3), padding = pad))\n",
    "    model.add(LeakyReLU(alpha = 0.1))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    #Fully Connected Layer\n",
    "    model.add(Flatten())\n",
    "    #Xavier initialization of the weights \n",
    "    model.add(Dense(units = 512, kernel_initializer = 'glorot_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    #Compiling the CNN\n",
    "    print('[INFO] compiling model...')\n",
    "    opt = Adam(lr = learnrate, decay = learnrate / EPOCHS)\n",
    "    model.compile(optimizer = opt, loss = 'categorical_crossentropy',\n",
    "                       metrics = ['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "    \n",
    "def fit_model(dataset, learnrate, EPOCHS, batch, height = 56, width = 56):\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                       shear_range = 0.2,\n",
    "                                       zoom_range = 0.2,\n",
    "                                       horizontal_flip = True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    training_set = train_datagen.flow_from_directory(dataset + '/train', target_size = (height, width), batch_size = batch, class_mode = 'categorical')\n",
    "\n",
    "    test_set = test_datagen.flow_from_directory(dataset + '/test', target_size = (height, width), batch_size = batch, class_mode = 'categorical')\n",
    "    \n",
    "    #count(dataset + '/train')\n",
    "    #num_classes = len(classes)\n",
    "    #model = build(num_classes, learnrate, EPOCHS, input_size = (height, width))\n",
    "    print('[INFO] training network')\n",
    "    history = model.fit_generator(training_set, steps_per_epoch = number_training, epochs = EPOCHS, validation_data = test_set, validation_steps = number_tested)\n",
    "    \n",
    "    print(\"[INFO] serializing network...\")\n",
    "\n",
    "    #H = model.save(args[\"model\"])\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "    plt.savefig('AccuracyResult.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "    plt.savefig('LossResult.png')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for d in ['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']:\n",
    "    with tf.device(d):\n",
    "        num_classes = len(classes)\n",
    "        model = build(num_classes, learnrate = 0.0001, EPOCHS = 5, pad = 'valid', input_size = (56, 56, 3))\n",
    "        fit_model(dataset = '../boats_train_test', learnrate = 0.0001, EPOCHS = 5, batch = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    #Could not figure out how to resolve errors when below code was in fit_model()\n",
    "    \n",
    "    #Sklearn metrics and Confusion matrix\n",
    "    predictions = model.predict(test_set, steps = number_tested)\n",
    "    # Get most likely class\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    #Correct classes\n",
    "    true_classes = test_set.classes\n",
    "    #class_labels = list(test_set.class_indices.keys())\n",
    "    #metrics\n",
    "    report = metrics.classification_report(true_classes, predicted_classes)\n",
    "    print(report) \n",
    "    #confusion matrix\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true = true_classes, y_pred = predicted_classes)\n",
    "    print(confusion_matrix)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initvgg(train_dir, batch):\n",
    "    K.clear_session()\n",
    "    #Initialize the VGG model without the Fully Connected Layers, \n",
    "    #thus we can train the model again on our dataset\n",
    "    global vgg16_model\n",
    "    vgg16_model = VGG16(include_top = False, weights = 'imagenet',\n",
    "                   input_shape = (224, 224, 3))\n",
    "    \n",
    "    height = 224\n",
    "    width = 224\n",
    "\n",
    "    #train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                       #shear_range = 0.2,\n",
    "                                       #zoom_range = 0.2,\n",
    "                                       #horizontal_flip = True)\n",
    "    \n",
    "    #train_datagen =  ImageDataGenerator(preprocessing_function = preprocess_input, \n",
    "     #                               rotation_range = 90, horizontal_flip = True,\n",
    "    #                              vertical_flip = True)\n",
    "    \n",
    "    #train_generator = train_datagen.flow_from_directory(train_dir, target_size = (height, width), batch_size = batch)\n",
    "    \n",
    "\n",
    "def build_transfer_model(vgg16_model, dropout, fc_layers, num_classes):\n",
    "    for layer in vgg16_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = vgg16_model.output\n",
    "    x = Flatten()(x)\n",
    "    for fc in fc_layers:\n",
    "        # New FC layer, random init\n",
    "        x = Dense(fc, activation='relu')(x) \n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "    # New softmax layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x) \n",
    "    \n",
    "    transfer_model = Model(inputs=vgg16_model.input, outputs=predictions)\n",
    "\n",
    "    return transfer_model\n",
    "\n",
    "def fit_transfer_model(dataset, EPOCHS, batch, FC_layers = [512], dropout = 0.5, learnrate = 0.00001):\n",
    "\n",
    "    #count(dataset + '/train')\n",
    "    EPOCHS = EPOCHS\n",
    "#    transfer_model = build_transfer_model(vgg16_model, \n",
    "#                                      dropout=dropout, \n",
    "#                                      fc_layers=FC_layers, \n",
    "#                                      num_classes=len(classes))\n",
    "\n",
    "    adam = Adam(lr=learnrate)\n",
    "    transfer_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    #filepath=\"./checkpoints/\" + \"ResNet50\" + \"_model_weights.h5\"\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n",
    "    #callbacks_list = [checkpoint]\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "    training_set = train_datagen.flow_from_directory(dataset + '/train', target_size = (224, 224), batch_size = batch, class_mode = 'categorical')\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    test_set = test_datagen.flow_from_directory(dataset + '/test', target_size = (224, 224), batch_size = batch, class_mode = 'categorical')\n",
    "\n",
    "    \n",
    "    print('[INFO] training network')\n",
    "    history = transfer_model.fit_generator(training_set, epochs = EPOCHS, workers=8, steps_per_epoch = number_training // batch, validation_data = test_set, validation_steps = number_tested // batch, shuffle=True)\n",
    "    \n",
    "    print(\"[INFO] serializing network...\")\n",
    "    #global H\n",
    "    #H = model.save(args[\"model\"])\n",
    "    \n",
    "    \n",
    "def evaluate_transfer_model():    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "    plt.savefig('AccuracyResult.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "    plt.savefig('LossResult.png')\n",
    "    plt.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for d in ['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']:\n",
    "    with tf.device(d):\n",
    "        initvgg(train_dir = '../boats_train_test/train', batch = 8)\n",
    "        transfer_model = build_transfer_model(vgg16_model, dropout=0.5, fc_layers=[512], num_classes=len(classes))\n",
    "        fit_transfer_model(dataset = '../boats_train_test', EPOCHS = 5, batch = 8)\n",
    "        evaluate_transfer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "initvgg(train_dir = '../boats_train_test/train', batch = 8)\n",
    "transfer_model = build_transfer_model(vgg16_model, dropout=0.5, fc_layers=[512], num_classes=len(classes))\n",
    "history = fit_transfer_model(dataset = '../boats_train_test', EPOCHS = 5, batch = 8, learnrate = 0.0001)\n",
    "evaluate_transfer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Could not figure resolve issues with code below when in evaluate_transfer_model()\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = EPOCHS\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"VGG16 Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig('VGGresults.png')\n",
    "    \n",
    "    #Sklearn metrics and Confusion matrix\n",
    "    predictions = model.predict_generator(test_set, steps = number_tested)\n",
    "    # Get most likely class\n",
    "    predicted_classes = numpy.argmax(predictions, axis=1)\n",
    "    #Correct classes\n",
    "    true_classes = test_set.classes\n",
    "    #class_labels = list(test_set.class_indices.keys())\n",
    "    #metrics\n",
    "    report = metrics.classification_report(true_classes, predicted_classes)\n",
    "    print(report) \n",
    "    #confusion matrix\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true = true_classes, y_pred = predicted_classes)\n",
    "    print(confusion_matrix)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
